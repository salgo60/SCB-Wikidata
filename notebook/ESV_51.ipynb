{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3524b76c-e64e-4d4b-9558-aa468c40b75b",
   "metadata": {},
   "source": [
    "ESV.com omdireigeras till Statskontoret.se \n",
    "\n",
    "* [#51](https://github.com/salgo60/SCB-Wikidata/issues/51)\n",
    "* Notebook [ESV_51.ipynb](http://localhost:8888/notebooks/SCB-Wikidata/notebook/ESV_51.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb05334-7f3d-4f42-a530-a23f63b92a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2026-01-09 13:29:21\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.timestamp()\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Start:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6a82537-c17f-4829-b710-5efd3847a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SCRIPT_NAME = \"ESV_51.ipynb.ipynb\"\n",
    "SCRIPT_URL = (\n",
    "    \"https://github.com/salgo60/SCB-Wikidata/\"\n",
    "    \"blob/master/notebook/ESV_51.ipynb\"\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d1071c5-e9da-4c62-94e5-29dd58a0a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_domains(file_path):\n",
    "    print(f\"[DEBUG] Reading domains from: {file_path}\")\n",
    "    df = pd.read_csv(file_path, header=0)   # <- skip header row\n",
    "    domains_list = df.iloc[:, 0].dropna().unique().tolist()\n",
    "    print(f\"[DEBUG] Found {len(domains_list)} domains.\")\n",
    "    return domains_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "501ae6a2-61cb-4280-a57f-74b631e28370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_sitematrix_df():\n",
    "    url = \"https://meta.wikimedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"sitematrix\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"salgo60-language-fetcher/1.0 (salgo60@msn.com)\"\n",
    "    }\n",
    "\n",
    "    print(\"[DEBUG] Fetching sitematrix‚Ä¶\")\n",
    "    r = requests.get(url, params=params, headers=headers)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if \"application/json\" not in r.headers.get(\"Content-Type\", \"\"):\n",
    "        raise ValueError(\"Server returned non-JSON response\")\n",
    "\n",
    "    data = r.json()[\"sitematrix\"]\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # --- language-specific sites ---\n",
    "    for key, lang_block in data.items():\n",
    "        if not key.isdigit():\n",
    "            continue  # skip \"count\", \"specials\"\n",
    "\n",
    "        lang_code = lang_block.get(\"code\")\n",
    "        lang_name = lang_block.get(\"name\")\n",
    "\n",
    "        for site in lang_block.get(\"site\", []):\n",
    "            rows.append({\n",
    "                \"lang_code\": lang_code,\n",
    "                \"lang_name\": lang_name,\n",
    "                \"project\": site.get(\"project\"),\n",
    "                \"url\": site.get(\"url\"),\n",
    "                \"dbname\": site.get(\"dbname\"),\n",
    "                \"site_name\": site.get(\"sitename\"),\n",
    "                \"closed\": site.get(\"closed\", False)\n",
    "            })\n",
    "\n",
    "    # --- special wikis (Wikidata, Commons, Meta, etc.) ---\n",
    "    for site in data.get(\"specials\", []):\n",
    "        rows.append({\n",
    "            \"lang_code\": \"special\",\n",
    "            \"lang_name\": \"special\",\n",
    "            \"project\": site.get(\"project\"),\n",
    "            \"url\": site.get(\"url\"),\n",
    "            \"dbname\": site.get(\"dbname\"),\n",
    "            \"site_name\": site.get(\"sitename\"),\n",
    "            \"closed\": site.get(\"closed\", False)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "537f187d-d45f-4d20-91b6-6d92c9e10b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Fetching sitematrix‚Ä¶\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 184 entries, 0 to 937\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   lang_code  184 non-null    object\n",
      " 1   lang_name  183 non-null    object\n",
      " 2   project    0 non-null      object\n",
      " 3   url        184 non-null    object\n",
      " 4   dbname     184 non-null    object\n",
      " 5   site_name  184 non-null    object\n",
      " 6   closed     184 non-null    bool  \n",
      "dtypes: bool(1), object(6)\n",
      "memory usage: 10.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"salgo60-language-fetcher/2.0 (https://github.com/salgo60)\"\n",
    "}\n",
    "\n",
    "\n",
    "df_lang_fetch = fetch_sitematrix_df()\n",
    "df_lang_fetch[\"closed\"] = df_lang_fetch[\"closed\"].fillna(False).astype(bool)\n",
    "\n",
    "df_lang_wikipedia = df_lang_filtered = df_lang_fetch[\n",
    "    (df_lang_fetch[\"site_name\"] == \"Wikipedia\") &\n",
    "    (df_lang_fetch[\"lang_name\"].str.lower() != \"special\")]\n",
    "\n",
    "#df_lang_wikipedia.to_csv(\"test.csv\")\n",
    "df_lang_wikipedia.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "089f90df-63f5-423e-b2c1-253aaedef223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/salgo/Documents/GitHub/SCB-Wikidata/notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14e7be1f-3a95-43f9-9a20-9e1386f497b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Reading domains from: sources/domains_ESV.csv\n",
      "[DEBUG] Found 1 domains.\n",
      "['esv.se']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from tqdm.notebook import tqdm\n",
    "file_path_domain = \"sources/domains_ESV.csv\"\n",
    "domains = read_domains(file_path_domain)\n",
    "print(domains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70fd4ae3-d846-482a-a0b5-a1b259a52448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Fetch exturlusage entries for one lang/domain\n",
    "# -----------------------------------------------------------\n",
    "def fetch_exturlusage(lang, domain):\n",
    "    base = f\"https://{lang}.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"list\": \"exturlusage\",\n",
    "        \"euquery\": domain,\n",
    "        \"eulimit\": \"max\"\n",
    "    }\n",
    "    while True:\n",
    "        r = session.get(base, params=params, timeout=10)\n",
    "        try:\n",
    "            data = r.json()\n",
    "        except ValueError:\n",
    "            print(f\"[WARN] {lang}: JSON decode failed\")\n",
    "            break\n",
    "\n",
    "        for item in data.get(\"query\", {}).get(\"exturlusage\", []):\n",
    "            yield {\n",
    "                \"lang\": lang,\n",
    "                \"page_title\": item.get(\"title\"),\n",
    "                \"url\": item.get(\"url\"),\n",
    "                \"wiki_link\": f\"https://{lang}.wikipedia.org/wiki/{item.get('title').replace(' ', '_')}\"\n",
    "            }\n",
    "\n",
    "        if \"continue\" not in data:\n",
    "            break\n",
    "        params.update(data[\"continue\"])\n",
    "        time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ed08c0f-0c0c-423f-b50f-442428865fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal Spr√•k: 184\n",
      "aa https://aa.wikipedia.org Qaf√°r af  -  0\n",
      "ace https://ace.wikipedia.org Ac√®h  -  0\n",
      "af https://af.wikipedia.org Afrikaans  -  0\n",
      "ak https://ak.wikipedia.org None  -  0\n",
      "ami https://ami.wikipedia.org Pangcah  -  0\n",
      "an https://an.wikipedia.org aragon√©s  -  0\n",
      "ast https://ast.wikipedia.org asturianu  -  0\n",
      "av https://av.wikipedia.org –∞–≤–∞—Ä  -  0\n",
      "avk https://avk.wikipedia.org Kotava  -  0\n",
      "ay https://ay.wikipedia.org Aymar aru  -  0\n",
      "bar https://bar.wikipedia.org Boarisch  -  0\n",
      "bbc https://bbc.wikipedia.org Batak Toba  -  0\n",
      "bcl https://bcl.wikipedia.org Bikol Central  -  0\n",
      "bi https://bi.wikipedia.org Bislama  -  0\n",
      "bm https://bm.wikipedia.org bamanankan  -  0\n",
      "bo https://bo.wikipedia.org ‡Ωñ‡Ωº‡Ωë‡ºã‡Ω°‡Ω≤‡ΩÇ  -  0\n",
      "br https://br.wikipedia.org brezhoneg  -  0\n",
      "bs https://bs.wikipedia.org bosanski  -  0\n",
      "btm https://btm.wikipedia.org Batak Mandailing  -  0\n",
      "bug https://bug.wikipedia.org Basa Ugi  -  0\n",
      "bxr https://bxr.wikipedia.org –±—É—Ä—è–∞–¥  -  0\n",
      "cbk-zam https://cbk-zam.wikipedia.org Chavacano de Zamboanga  -  0\n",
      "cdo https://cdo.wikipedia.org Èñ©Êù±Ë™û / M√¨ng-dƒïÃ§ng-ng·π≥ÃÑ  -  0\n",
      "ceb https://ceb.wikipedia.org Cebuano  -  0\n",
      "ch https://ch.wikipedia.org Chamoru  -  0\n",
      "cho https://cho.wikipedia.org Chahta anumpa  -  0\n",
      "chr https://chr.wikipedia.org ·è£·é≥·é©  -  0\n",
      "co https://co.wikipedia.org corsu  -  0\n",
      "cr https://cr.wikipedia.org Nƒìhiyawƒìwin / ·ìÄ·ê¶·êÉ·î≠·êç·êè·ê£  -  0\n",
      "csb https://csb.wikipedia.org kasz√´bsczi  -  0\n",
      "da https://da.wikipedia.org dansk  -  1\n",
      "de https://de.wikipedia.org Deutsch  -  1\n",
      "din https://din.wikipedia.org Thu…î≈ãj√§≈ã  -  0\n",
      "diq https://diq.wikipedia.org Zazaki  -  0\n",
      "dtp https://dtp.wikipedia.org Kadazandusun  -  0\n",
      "dz https://dz.wikipedia.org ‡Ωá‡Ωº‡ΩÑ‡ºã‡ΩÅ  -  0\n",
      "ee https://ee.wikipedia.org e ãegbe  -  0\n",
      "eml https://eml.wikipedia.org emili√†n e rumagn√≤l  -  0\n",
      "en https://en.wikipedia.org English  -  32\n",
      "es https://es.wikipedia.org espa√±ol  -  0\n",
      "eu https://eu.wikipedia.org euskara  -  0\n",
      "fat https://fat.wikipedia.org mfantse  -  0\n",
      "ff https://ff.wikipedia.org Fulfulde  -  0\n",
      "fi https://fi.wikipedia.org suomi  -  1\n",
      "fj https://fj.wikipedia.org Na Vosa Vakaviti  -  0\n",
      "fo https://fo.wikipedia.org f√∏royskt  -  0\n",
      "frr https://frr.wikipedia.org Nordfriisk  -  0\n",
      "gl https://gl.wikipedia.org galego  -  0\n",
      "glk https://glk.wikipedia.org ⁄Ø€åŸÑ⁄©€å  -  0\n",
      "gor https://gor.wikipedia.org Bahasa Hulontalo  -  0\n",
      "got https://got.wikipedia.org êå≤êåøêçÑêåπêçÉêå∫  -  0\n",
      "gpe https://gpe.wikipedia.org Ghanaian Pidgin  -  0\n",
      "[WARN] gsw: JSON decode failed\n",
      "gsw https://als.wikipedia.org Alemannisch  -  0\n",
      "guw https://guw.wikipedia.org gungbe  -  0\n",
      "gv https://gv.wikipedia.org Gaelg  -  0\n",
      "ha https://ha.wikipedia.org Hausa  -  0\n",
      "hak https://hak.wikipedia.org ÂÆ¢ÂÆ∂Ë™û / Hak-k√¢-ng√Æ  -  0\n",
      "haw https://haw.wikipedia.org Hawai ªi  -  0\n",
      "hif https://hif.wikipedia.org Fiji Hindi  -  0\n",
      "ho https://ho.wikipedia.org Hiri Motu  -  0\n",
      "hz https://hz.wikipedia.org Otsiherero  -  0\n",
      "ia https://ia.wikipedia.org interlingua  -  0\n",
      "iba https://iba.wikipedia.org Jaku Iban  -  0\n",
      "id https://id.wikipedia.org Bahasa Indonesia  -  0\n",
      "ie https://ie.wikipedia.org Interlingue  -  0\n",
      "ig https://ig.wikipedia.org Igbo  -  0\n",
      "ii https://ii.wikipedia.org ÍÜáÍâô  -  0\n",
      "ik https://ik.wikipedia.org I√±upiatun  -  0\n",
      "ilo https://ilo.wikipedia.org Ilokano  -  0\n",
      "is https://is.wikipedia.org √≠slenska  -  0\n",
      "it https://it.wikipedia.org italiano  -  1\n",
      "ja https://ja.wikipedia.org Êó•Êú¨Ë™û  -  0\n",
      "jbo https://jbo.wikipedia.org la .lojban.  -  0\n",
      "kaa https://kaa.wikipedia.org Qaraqalpaqsha  -  0\n",
      "kab https://kab.wikipedia.org Taqbaylit  -  0\n",
      "kcg https://kcg.wikipedia.org Tyap  -  0\n",
      "kg https://kg.wikipedia.org Kongo  -  0\n",
      "ki https://ki.wikipedia.org Gƒ©k≈©y≈©  -  0\n",
      "kj https://kj.wikipedia.org Kwanyama  -  0\n",
      "kl https://kl.wikipedia.org kalaallisut  -  0\n",
      "knc https://knc.wikipedia.org Yerwa Kanuri  -  0\n",
      "kr https://kr.wikipedia.org kanuri  -  0\n",
      "ksh https://ksh.wikipedia.org Ripoarisch  -  0\n",
      "kv https://kv.wikipedia.org –∫–æ–º–∏  -  0\n",
      "kw https://kw.wikipedia.org kernowek  -  0\n",
      "lb https://lb.wikipedia.org L√´tzebuergesch  -  0\n",
      "lg https://lg.wikipedia.org Luganda  -  0\n",
      "li https://li.wikipedia.org Limburgs  -  0\n",
      "lij https://lij.wikipedia.org Ligure  -  0\n",
      "lld https://lld.wikipedia.org Ladin  -  0\n",
      "lmo https://lmo.wikipedia.org lombard  -  0\n",
      "ln https://ln.wikipedia.org ling√°la  -  0\n",
      "mad https://mad.wikipedia.org Madhur√¢  -  0\n",
      "map-bms https://map-bms.wikipedia.org Basa Banyumasan  -  0\n",
      "mg https://mg.wikipedia.org Malagasy  -  0\n",
      "mh https://mh.wikipedia.org Ebon  -  0\n",
      "mi https://mi.wikipedia.org MƒÅori  -  0\n",
      "min https://min.wikipedia.org Minangkabau  -  0\n",
      "ms https://ms.wikipedia.org Bahasa Melayu  -  1\n",
      "mus https://mus.wikipedia.org Mvskoke  -  0\n",
      "na https://na.wikipedia.org Dorerin Naoero  -  0\n",
      "nan https://zh-min-nan.wikipedia.org Èñ©ÂçóË™û / B√¢n-l√¢m-g√≠  -  0\n",
      "nap https://nap.wikipedia.org Napulitano  -  0\n",
      "nds https://nds.wikipedia.org Plattd√º√ºtsch  -  0\n",
      "nds-nl https://nds-nl.wikipedia.org Nedersaksies  -  0\n",
      "new https://new.wikipedia.org ‡§®‡•á‡§™‡§æ‡§≤ ‡§≠‡§æ‡§∑‡§æ  -  0\n",
      "ng https://ng.wikipedia.org Oshiwambo  -  0\n",
      "nia https://nia.wikipedia.org Li Niha  -  0\n",
      "nl https://nl.wikipedia.org Nederlands  -  0\n",
      "nn https://nn.wikipedia.org norsk nynorsk  -  0\n",
      "no https://no.wikipedia.org norsk  -  4\n",
      "nov https://nov.wikipedia.org Novial  -  0\n",
      "nrm https://nrm.wikipedia.org Nouormand  -  0\n",
      "nso https://nso.wikipedia.org Sesotho sa Leboa  -  0\n",
      "nup https://nup.wikipedia.org Nupe  -  0\n",
      "nv https://nv.wikipedia.org Din√© bizaad  -  0\n",
      "ny https://ny.wikipedia.org Chi-Chewa  -  0\n",
      "om https://om.wikipedia.org Oromoo  -  0\n",
      "pag https://pag.wikipedia.org Pangasinan  -  0\n",
      "pam https://pam.wikipedia.org Kapampangan  -  0\n",
      "pap https://pap.wikipedia.org Papiamentu  -  0\n",
      "pcd https://pcd.wikipedia.org Picard  -  0\n",
      "pcm https://pcm.wikipedia.org Naij√°  -  0\n",
      "pdc https://pdc.wikipedia.org Deitsch  -  0\n",
      "pfl https://pfl.wikipedia.org P√§lzisch  -  0\n",
      "pi https://pi.wikipedia.org ‡§™‡§æ‡§≤‡§ø  -  0\n",
      "pih https://pih.wikipedia.org Norfuk / Pitkern  -  0\n",
      "pl https://pl.wikipedia.org polski  -  0\n",
      "pms https://pms.wikipedia.org Piemont√®is  -  0\n",
      "pwn https://pwn.wikipedia.org pinayuanan  -  0\n",
      "qu https://qu.wikipedia.org Runa Simi  -  0\n",
      "rm https://rm.wikipedia.org rumantsch  -  0\n",
      "rn https://rn.wikipedia.org ikirundi  -  0\n",
      "ro https://ro.wikipedia.org rom√¢nƒÉ  -  0\n",
      "roa-tara https://roa-tara.wikipedia.org tarand√≠ne  -  0\n",
      "[WARN] rup: JSON decode failed\n",
      "rup https://roa-rup.wikipedia.org arm√£neashti  -  0\n",
      "rw https://rw.wikipedia.org Ikinyarwanda  -  0\n",
      "sc https://sc.wikipedia.org sardu  -  0\n",
      "scn https://scn.wikipedia.org sicilianu  -  0\n",
      "sco https://sco.wikipedia.org Scots  -  0\n",
      "se https://se.wikipedia.org davvis√°megiella  -  0\n",
      "sg https://sg.wikipedia.org S√§ng√∂  -  0\n",
      "sgs https://bat-smg.wikipedia.org ≈æemaitƒó≈°ka  -  0\n",
      "shi https://shi.wikipedia.org Tacl·∏•it  -  0\n",
      "simple https://simple.wikipedia.org Simple English  -  0\n",
      "sm https://sm.wikipedia.org Gagana Samoa  -  0\n",
      "smn https://smn.wikipedia.org anar√¢≈°kiel√¢  -  0\n",
      "sn https://sn.wikipedia.org chiShona  -  0\n",
      "so https://so.wikipedia.org Soomaaliga  -  0\n",
      "sq https://sq.wikipedia.org shqip  -  2\n",
      "srn https://srn.wikipedia.org Sranantongo  -  0\n",
      "ss https://ss.wikipedia.org SiSwati  -  0\n",
      "st https://st.wikipedia.org Sesotho  -  0\n",
      "stq https://stq.wikipedia.org Seeltersk  -  0\n",
      "su https://su.wikipedia.org Sunda  -  0\n",
      "sv https://sv.wikipedia.org svenska  -  111\n",
      "sw https://sw.wikipedia.org Kiswahili  -  0\n",
      "szl https://szl.wikipedia.org ≈õl≈Ønski  -  0\n",
      "tet https://tet.wikipedia.org tetun  -  0\n",
      "tl https://tl.wikipedia.org Tagalog  -  0\n",
      "tn https://tn.wikipedia.org Setswana  -  0\n",
      "to https://to.wikipedia.org lea faka-Tonga  -  0\n",
      "tpi https://tpi.wikipedia.org Tok Pisin  -  0\n",
      "ts https://ts.wikipedia.org Xitsonga  -  0\n",
      "tt https://tt.wikipedia.org —Ç–∞—Ç–∞—Ä—á–∞ / tatar√ßa  -  0\n",
      "tum https://tum.wikipedia.org chiTumbuka  -  0\n",
      "tw https://tw.wikipedia.org Twi  -  0\n",
      "ty https://ty.wikipedia.org reo tahiti  -  0\n",
      "ug https://ug.wikipedia.org ÿ¶€áŸäÿ∫€áÿ±⁄Ü€ï / Uyghurche  -  0\n",
      "ve https://ve.wikipedia.org Tshivenda  -  0\n",
      "vec https://vec.wikipedia.org v√®neto  -  0\n",
      "vi https://vi.wikipedia.org Ti·∫øng Vi·ªát  -  0\n",
      "vls https://vls.wikipedia.org West-Vlams  -  0\n",
      "vro https://fiu-vro.wikipedia.org v√µro  -  0\n",
      "wa https://wa.wikipedia.org walon  -  0\n",
      "war https://war.wikipedia.org Winaray  -  0\n",
      "wo https://wo.wikipedia.org Wolof  -  0\n",
      "xal https://xal.wikipedia.org —Ö–∞–ª—å–º–≥  -  0\n",
      "xh https://xh.wikipedia.org isiXhosa  -  0\n",
      "yo https://yo.wikipedia.org Yor√πb√°  -  0\n",
      "za https://za.wikipedia.org Vahcuengh  -  0\n",
      "zea https://zea.wikipedia.org Ze√™uws  -  0\n",
      "zh https://zh.wikipedia.org ‰∏≠Êñá  -  1\n",
      "zu https://zu.wikipedia.org isiZulu  -  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Session & helpers\n",
    "# -------------------------\n",
    "session = requests.Session()\n",
    "session.headers.update({\"User-Agent\": \"SCB-LinkAudit/1.0 (https://www.scb.se/)\"})\n",
    "\n",
    "# we need some filtering  \n",
    "\n",
    "print(\"Antal Spr√•k:\",len(df_lang_wikipedia ))\n",
    "results = []\n",
    "for _, row in df_lang_wikipedia.iterrows():\n",
    "    lang = row[\"lang_code\"]\n",
    "    url  = row[\"url\"]\n",
    "    lang_name = row[\"lang_name\"]\n",
    "    before = len(results)\n",
    "    #print(lang, url, lang_name,domains)\n",
    "    for entry in fetch_exturlusage(lang, domains):\n",
    "        results.append(entry)     \n",
    "    after = len(results) \n",
    "    links = after-before\n",
    "    print(lang, url, lang_name,\" - \", links)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e133147-9793-481d-afee-3f3e0bb30de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 155 entries, 0 to 154\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   lang        155 non-null    object\n",
      " 1   page_title  155 non-null    object\n",
      " 2   url         155 non-null    object\n",
      " 3   wiki_link   155 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_esv = pd.DataFrame(results)\n",
    "df_esv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b33b6741-35d8-4225-884c-e5d9e4a41a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total links: 155\n",
      "Total unique links: 112\n",
      "Number of languages: 10\n",
      "\n",
      "Languages with most links:\n",
      "lang\n",
      "sv    111\n",
      "en     32\n",
      "no      4\n",
      "sq      2\n",
      "da      1\n",
      "de      1\n",
      "fi      1\n",
      "it      1\n",
      "ms      1\n",
      "zh      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Stats ---\n",
    "total_links = len(df_esv)\n",
    "total_unique_links = df_esv['url'].nunique()\n",
    "num_languages = df_esv['lang'].nunique()\n",
    "langs_sorted = df_esv['lang'].value_counts()\n",
    "\n",
    "print(\"Total links:\", total_links)\n",
    "print(\"Total unique links:\", total_unique_links)\n",
    "print(\"Number of languages:\", num_languages)\n",
    "print(\"\\nLanguages with most links:\")\n",
    "print(langs_sorted.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7bbdd98b-49de-447e-a298-f18e71b5d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stats ---\n",
    "total_links = len(df_esv)\n",
    "total_unique_links = df_esv[\"url\"].nunique()\n",
    "langs_with_hits = sorted(df_esv[\"lang\"].unique())\n",
    "\n",
    "num_languages_found = len(langs_with_hits)\n",
    "num_languages_checked = len(df_lang_wikipedia)        # alla spr√•k som genoms√∂ktes\n",
    "num_languages_found = df_esv['lang'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3539e03f-d954-4a73-a81c-eed4aef5f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_languages_checked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43f162d4-49f1-4990-9312-705455c299e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "SOFT_404_PHRASES = [\n",
    "    \"Sidan kan inte hittas\",\n",
    "    \"sidan tagits bort\",\n",
    "    \"felaktig adress\",\n",
    "    \"kontakta registrator\",\n",
    "    \"Regeringskansliets arkiv\",\n",
    "]\n",
    "\n",
    "ROOT_CANONICAL = \"https://www.esv.se\"\n",
    "\n",
    "\n",
    "def norm(u):\n",
    "    return u.rstrip(\"/\").lower()\n",
    "\n",
    "\n",
    "def check_url(url, timeout=15):\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            url,\n",
    "            allow_redirects=True,\n",
    "            timeout=timeout,\n",
    "            headers={\n",
    "                \"User-Agent\": \"LinkChecker/1.0 (research; salgo60@msn.com)\"\n",
    "            }\n",
    "        )\n",
    "    except RequestException as e:\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"status\": \"error\",\n",
    "            \"reason\": str(e),\n",
    "        }\n",
    "\n",
    "    final_url = r.url\n",
    "    status_code = r.status_code\n",
    "    text = r.text or \"\"\n",
    "\n",
    "    # 1. Hard HTTP error\n",
    "    if status_code >= 400:\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"status\": \"dead\",\n",
    "            \"reason\": f\"HTTP {status_code}\",\n",
    "            \"final_url\": final_url,\n",
    "        }\n",
    "\n",
    "    # 2. Redirected to site root (content missing)\n",
    "    if norm(final_url) == norm(ROOT_CANONICAL) and norm(url) != norm(final_url):\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"status\": \"dead\",\n",
    "            \"reason\": \"redirect_to_root\",\n",
    "            \"final_url\": final_url,\n",
    "        }\n",
    "\n",
    "    # 3. Soft 404 detection\n",
    "    lowered = text.lower()\n",
    "    for phrase in SOFT_404_PHRASES:\n",
    "        if phrase.lower() in lowered:\n",
    "            return {\n",
    "                \"url\": url,\n",
    "                \"status\": \"dead\",\n",
    "                \"reason\": \"soft_404\",\n",
    "                \"final_url\": final_url,\n",
    "            }\n",
    "\n",
    "    # 4. Otherwise OK\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"status\": \"ok\",\n",
    "        \"final_url\": final_url,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe7ffd37-e59a-47f7-8c12-86dd1fc075ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_internet_archive(url, timeout=10):\n",
    "    api = \"https://archive.org/wayback/available\"\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            api,\n",
    "            params={\"url\": url},\n",
    "            timeout=timeout,\n",
    "            headers={\"User-Agent\": \"LinkChecker/1.0\"}\n",
    "        )\n",
    "        data = r.json()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    snap = data.get(\"archived_snapshots\", {}).get(\"closest\")\n",
    "    if snap and snap.get(\"available\"):\n",
    "        return snap.get(\"url\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82640cc4-bdeb-4d2f-96f4-3dd0f09d9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 155 entries, 0 to 154\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   lang        155 non-null    object\n",
      " 1   page_title  155 non-null    object\n",
      " 2   url         155 non-null    object\n",
      " 3   wiki_link   155 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_esv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491bd33f-5a22-4fd2-b8a9-ad0406149fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking esv.se links:  42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 47/112 [02:05<02:15,  2.09s/link]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  \n",
    "import time\n",
    "results = []\n",
    "checked = set() \n",
    "urls = df_esv[\"url\"].dropna().astype(str).unique()\n",
    "for url in tqdm(\n",
    "    urls,\n",
    "    total=len(urls),\n",
    "    desc=\"Checking esv.se links\",\n",
    "    unit=\"link\",\n",
    "):\n",
    "    #print(\"url:\", url)\n",
    "    if url in checked:\n",
    "        continue\n",
    "    result = check_url(url)  \n",
    "    ia_url = check_internet_archive(url)\n",
    "    result[\"ia_url\"] = ia_url\n",
    "    result[\"ia_status\"] = \"available\" if ia_url else \"missing\"\n",
    "    results.append(result)\n",
    "    checked.add(url)\n",
    "    time.sleep(0.3)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52c48b-1253-4364-9e54-5d798e9f8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARD RESET\n",
    "df_results = None\n",
    "\n",
    "print(\"len(results):\", len(results))\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "print(\"df_results.shape:\", df_results.shape)\n",
    "print(df_results.head(2))\n",
    "print(df_results.tail(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed8b8d-3327-47c6-8cbc-6c54cc151e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(results):\", len(results))\n",
    "print(\"first:\", results[0])\n",
    "print(\"last:\", results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751aecec-1fa3-424d-a461-f40479ecfec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac75f6-aebb-4fe7-8b9c-f17a83795119",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_results[\"status\"] == \"dead\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d86ab-1f35-4189-8795-ace32a57a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\n",
    "    (df_results[\"status\"] == \"dead\") &\n",
    "    (df_results[\"ia_status\"] != \"available\")\n",
    "].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c85f75-8f29-4d4a-be5b-acd4a1f18772",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb3d63d-01fe-4452-adf9-3c44465eea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_results = pd.DataFrame(results)  \n",
    "df_results = (\n",
    "    pd.DataFrame(results)\n",
    "    .drop_duplicates(subset=\"url\", keep=\"last\")\n",
    ")\n",
    "df_esv = df_esv.merge(\n",
    "    df_results,\n",
    "    on=\"url\",\n",
    "    how=\"left\",\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ffcd7-d090-4905-b456-f19fc77bb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042d0c3-9261-48be-af92-4a1ec44f4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_counts = df_esv[\"status\"].value_counts()\n",
    "\n",
    "num_ok = status_counts.get(\"ok\", 0)\n",
    "num_dead = status_counts.get(\"dead\", 0)\n",
    "num_error = status_counts.get(\"error\", 0)\n",
    "num_total = len(status_counts)\n",
    "print( \"Ok \",num_ok) \n",
    "print( \"Dead \",num_dead)\n",
    "print( \"Error \",num_error ) \n",
    "print( \"Total \",num_total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd84212c-57c9-4fc0-9017-8e667346e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esv[\"reason\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b994c35-21ff-4668-a862-6963a7d70a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import os\n",
    "\n",
    "# S√§tt datum\n",
    "today = date.today().strftime(\"%Y_%m_%d\")\n",
    "\n",
    "# Se till att katalogen finns\n",
    "os.makedirs(\"resultsESV\", exist_ok=True)\n",
    "\n",
    "# Bygg filnamn\n",
    "outfile = f\"resultsESV/links_ESV_v1_{today}.csv\"\n",
    "\n",
    "# Exportera\n",
    "df_esv.to_csv(outfile, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[OK] Exported {len(df_esv)} rows to {outfile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c744793-df08-4d4a-b8e6-e34bc8d76e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_stats = (\n",
    "    df_esv\n",
    "    .groupby(\"lang\")\n",
    "    .agg(\n",
    "        total_links=(\"url\", \"count\"),\n",
    "        broken_links=(\"status\", lambda s: (s == \"dead\").sum()),\n",
    "        archived_links=(\"ia_status\", lambda s: (s == \"available\").sum()),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "lang_stats[\"broken_pct\"] = (\n",
    "    100 * lang_stats[\"broken_links\"] / lang_stats[\"total_links\"]\n",
    ").round(1)\n",
    "\n",
    "lang_stats[\"broken_lost\"] = (\n",
    "    lang_stats[\"broken_links\"] - lang_stats[\"archived_links\"])\n",
    "\n",
    "top10_langs = (\n",
    "    lang_stats\n",
    "    .sort_values(\"total_links\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "top10_langs[\n",
    "    [\n",
    "        \"lang\",\n",
    "        \"total_links\",\n",
    "        \"broken_links\",\n",
    "        \"broken_pct\",\n",
    "        \"archived_links\",\n",
    "        \"broken_lost\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd7a04-3ca8-4970-9f11-7b13bd41f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (lang_stats[\"broken_links\"] <= lang_stats[\"total_links\"]).all()\n",
    "assert (lang_stats[\"broken_pct\"] <= 100).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c645ebb-362e-4a3f-b456-76ce1f6debca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "df = df_esv.copy()\n",
    "\n",
    "df[\"domain\"] = df[\"url\"].apply(\n",
    "    lambda u: urlparse(u).netloc.lower() if pd.notna(u) else None\n",
    ")\n",
    "domain_stats = (\n",
    "    df\n",
    "    .groupby(\"domain\")\n",
    "    .agg(\n",
    "        total_links=(\"url\", \"count\"),\n",
    "        broken_links=(\"status\", lambda s: (s == \"dead\").sum()),\n",
    "        error_links=(\"status\", lambda s: (s == \"error\").sum()),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "domain_stats[\"broken_pct\"] = (\n",
    "    100 * domain_stats[\"broken_links\"] / domain_stats[\"total_links\"]\n",
    ").round(1)\n",
    "\n",
    "domain_stats[\"error_pct\"] = (\n",
    "    100 * domain_stats[\"error_links\"] / domain_stats[\"total_links\"]\n",
    ").round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38394f21-3d1f-4646-b197-77833a64eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c446132-2e37-48a7-bbda-40b6cc7eb32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_counts = df[\"status\"].value_counts()\n",
    "\n",
    "num_ok = int(status_counts.get(\"ok\", 0))\n",
    "num_dead = int(status_counts.get(\"dead\", 0))\n",
    "num_error = int(status_counts.get(\"error\", 0))\n",
    "num_total = len(df)\n",
    "\n",
    "pct_ok = round(100 * num_ok / num_total, 1)\n",
    "pct_dead = round(100 * num_dead / num_total, 1)\n",
    "pct_error = round(100 * num_error / num_total, 1)\n",
    "\n",
    "# Broken links: archived vs lost\n",
    "num_dead_archived = df[\n",
    "    (df[\"status\"] == \"dead\") & (df[\"ia_status\"] == \"available\")\n",
    "].shape[0]\n",
    "\n",
    "num_dead_lost = num_dead - num_dead_archived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d8ac9-cff7-4d8c-b863-37dcdd771c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_domains = (\n",
    "    domain_stats[domain_stats[\"total_links\"] >= 5]\n",
    "    .sort_values(\"total_links\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "domain_stats_html = \"<ul>\"\n",
    "for _, r in top_domains.iterrows():\n",
    "    domain_stats_html += (\n",
    "        f\"<li><strong>{r['domain']}</strong>: \"\n",
    "        f\"{r['broken_links']} / {r['total_links']} broken \"\n",
    "        f\"({r['broken_pct']}%)</li>\"\n",
    "    )\n",
    "domain_stats_html += \"</ul>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037fe8c-d188-4388-a979-08d1c590ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_ok + num_dead + num_error  == num_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21373c9-81b2-4255-a75f-de8a5ed54305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date, datetime\n",
    "from urllib.parse import quote\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def save_sortable_html_df_regeringen(\n",
    "    df,\n",
    "    out_dir=\"resultsESV\",\n",
    "    domains=None,\n",
    "    issue_url=\"https://github.com/salgo60/SCB-Wikidata/issues/51\",\n",
    "):\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    today = date.today().strftime(\"%Y_%m_%d\")\n",
    "    out_path = out_dir / f\"links_esv_v1_{today}.html\"\n",
    "    rerun_ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "     # --- F√∂rbered data ---\n",
    "    df = df.copy()  \n",
    "    status_counts = df[\"status\"].value_counts()\n",
    "\n",
    "    num_ok = int(status_counts.get(\"ok\", 0))\n",
    "    num_dead = int(status_counts.get(\"dead\", 0))\n",
    "    num_error = int(status_counts.get(\"error\", 0))\n",
    "    num_total = len(df)\n",
    "    \n",
    "    pct_ok = round(100 * num_ok / num_total, 1)\n",
    "    pct_dead = round(100 * num_dead / num_total, 1)\n",
    "    pct_error = round(100 * num_error / num_total, 1)\n",
    "    \n",
    "    # Broken links: archived vs lost\n",
    "    num_dead_archived = df[\n",
    "        (df[\"status\"] == \"dead\") & (df[\"ia_status\"] == \"available\")\n",
    "    ].shape[0]\n",
    "    \n",
    "    num_dead_lost = num_dead - num_dead_archived\n",
    "\n",
    "    domains = domains or []\n",
    "    from urllib.parse import urlparse\n",
    "    \n",
    "    df[\"domain\"] = df[\"url\"].apply(\n",
    "        lambda u: urlparse(u).netloc.lower() if pd.notna(u) else None\n",
    "    )\n",
    "\n",
    "    domain_stats = (\n",
    "        df\n",
    "        .groupby(\"domain\")\n",
    "        .agg(\n",
    "            total_links=(\"url\", \"count\"),\n",
    "            broken_links=(\"status\", lambda s: (s == \"dead\").sum()),\n",
    "            error_links=(\"status\", lambda s: (s == \"error\").sum()),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    domain_stats[\"broken_pct\"] = (\n",
    "        100 * domain_stats[\"broken_links\"] / domain_stats[\"total_links\"]\n",
    "    ).round(1)\n",
    "    \n",
    "    domain_stats[\"error_pct\"] = (\n",
    "        100 * domain_stats[\"error_links\"] / domain_stats[\"total_links\"]\n",
    "    ).round(1)\n",
    "    \n",
    "    domain_stats[\"problem_pct\"] = (\n",
    "        100 * (domain_stats[\"broken_links\"] + domain_stats[\"error_links\"])\n",
    "        / domain_stats[\"total_links\"]\n",
    "    ).round(1)\n",
    "    \n",
    "\n",
    "    domain_stats_html = \"<ul>\"\n",
    "    for _, r in top_domains.iterrows():\n",
    "        domain_stats_html += (\n",
    "            f\"<li><strong>{r['domain']}</strong>: \"\n",
    "            f\"{r['broken_links']} / {r['total_links']} broken \"\n",
    "            f\"({r['broken_pct']}%)</li>\"\n",
    "        )\n",
    "    domain_stats_html += \"</ul>\"\n",
    "\n",
    "    domain_table_html = (\n",
    "        domain_stats\n",
    "        .head(20)\n",
    "        .to_html(\n",
    "            classes=\"pivot\",\n",
    "            border=0,\n",
    "            index=False,\n",
    "        )\n",
    "    )\n",
    "    lang_stats = (\n",
    "    df\n",
    "        .groupby(\"lang\")\n",
    "        .agg(\n",
    "            total_links=(\"url\", \"count\"),\n",
    "            broken_links=(\"status\", lambda s: (s == \"dead\").sum()),\n",
    "            error_links=(\"status\", lambda s: (s == \"error\").sum()),\n",
    "            broken_archived=(\"ia_status\", lambda s: (s == \"available\").sum()),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    lang_stats[\"broken_lost\"] = (\n",
    "        lang_stats[\"broken_links\"] - lang_stats[\"broken_archived\"]\n",
    "    )\n",
    "    \n",
    "    lang_stats[\"broken_pct\"] = (\n",
    "        100 * lang_stats[\"broken_links\"] / lang_stats[\"total_links\"]\n",
    "    ).round(1)\n",
    "    \n",
    "    lang_stats[\"problem_pct\"] = (\n",
    "        100 * (lang_stats[\"broken_links\"] + lang_stats[\"error_links\"])\n",
    "        / lang_stats[\"total_links\"]\n",
    "    ).round(1)\n",
    "\n",
    "    lang_stats = lang_stats.sort_values(\n",
    "        \"broken_links\",\n",
    "        ascending=False\n",
    "    )\n",
    " \n",
    "    lang_stats_display = lang_stats[\n",
    "        [\n",
    "            \"lang\",\n",
    "            \"total_links\",\n",
    "            \"broken_links\",\n",
    "            \"broken_archived\",\n",
    "            \"broken_lost\",\n",
    "            \"broken_pct\",\n",
    "            \"problem_pct\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    lang_table_html = (\n",
    "        lang_stats_display\n",
    "        .head(15)\n",
    "        .to_html(\n",
    "            classes=\"pivot\",\n",
    "            border=0,\n",
    "            index=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    STATUS_ICON = {\n",
    "        \"ok\":    (\"fa-circle-check\", \"#2e7d32\", \"OK\"),\n",
    "        \"dead\":  (\"fa-circle-xmark\", \"#c62828\", \"Broken link\"),\n",
    "        \"error\": (\"fa-triangle-exclamation\", \"#ef6c00\", \"Request error\"),\n",
    "    }\n",
    "    \n",
    "    if \"status\" in df.columns:\n",
    "        def render_status(r):\n",
    "            icon, color, label = STATUS_ICON.get(\n",
    "                r[\"status\"], (\"fa-question-circle\", \"#757575\", \"Unknown\")\n",
    "            )\n",
    "            reason = r.get(\"reason\", \"\")\n",
    "            return (\n",
    "                f'<span class=\"status-icon\" '\n",
    "                f'data-status=\"{r[\"status\"]}\" '\n",
    "                f'title=\"{label}: {reason}\" '\n",
    "                f'style=\"color:{color}; font-size:14px; cursor:pointer;\">'\n",
    "                f'<i class=\"fa-solid {icon}\"></i>'\n",
    "                f'</span>'\n",
    "            )\n",
    "        df.insert(\n",
    "            0,\n",
    "            \"status_icon\",\n",
    "            df.apply(render_status, axis=1)\n",
    "        )\n",
    "\n",
    "        def render_ia_icon(r):\n",
    "            if r.get(\"ia_status\") == \"available\" and r.get(\"ia_url\"):\n",
    "                return (\n",
    "                    f'<a href=\"{r[\"ia_url\"]}\" target=\"_blank\" '\n",
    "                    f'title=\"Archived copy (Internet Archive)\">'\n",
    "                    f'<i class=\"fa-solid fa-box-archive\" '\n",
    "                    f'style=\"color:#1565c0;\"></i>'\n",
    "                    f'</a>'\n",
    "                )\n",
    "            return \"\"\n",
    "        \n",
    "        df.insert(\n",
    "            1,\n",
    "            \"archive\",\n",
    "            df.apply(render_ia_icon, axis=1)\n",
    "        )\n",
    "\n",
    "\n",
    "    # Wikipedia: ikon + titel (byggd fr√•n lang + page_title)\n",
    "    if {\"lang\", \"page_title\"}.issubset(df.columns):\n",
    "        df[\"page_title\"] = df.apply(\n",
    "            lambda r: (\n",
    "                f'<a href=\"https://{r[\"lang\"]}.wikipedia.org/wiki/{quote(str(r[\"page_title\"]))}\" '\n",
    "                f'target=\"_blank\" title=\"Wikipedia ({r[\"lang\"]})\">'\n",
    "                f'<i class=\"fa-brands fa-wikipedia-w\" style=\"margin-right:6px;\"></i>'\n",
    "                f'{r[\"page_title\"]}</a>'\n",
    "                if pd.notna(r[\"lang\"]) and pd.notna(r[\"page_title\"])\n",
    "                else r[\"page_title\"]\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "    # Externa l√§nkar\n",
    "    for col in [\"Wikipedia-l√§nk\", \"Extern l√§nk\", \"url\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>' if pd.notna(x) else \"\"\n",
    "            )\n",
    "\n",
    "    # --- HTML-tabell ---\n",
    "    html_table = df.to_html(\n",
    "        classes=\"pivot\",\n",
    "        border=0,\n",
    "        escape=False,  # kr√§vs f√∂r HTML-l√§nkar\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    # --- CSS ---\n",
    "    css = \"\"\"\n",
    "    <style>\n",
    "      body {\n",
    "        font-family: Arial, sans-serif;\n",
    "        margin: 20px;\n",
    "      }\n",
    "      table.pivot {\n",
    "        border-collapse: collapse;\n",
    "        width: 100%;\n",
    "        font-size: 12px;\n",
    "      }\n",
    "      table.pivot th, table.pivot td {\n",
    "        border: 1px solid #999;\n",
    "        padding: 6px 8px;\n",
    "        text-align: left;\n",
    "        vertical-align: top;\n",
    "        white-space: normal;\n",
    "      }\n",
    "      table.pivot th {\n",
    "        cursor: pointer;\n",
    "        background: #f2f2f2;\n",
    "      }\n",
    "      table.pivot th:hover {\n",
    "        background: #e2e2e2;\n",
    "      }\n",
    "      table.pivot thead th {\n",
    "        position: sticky;\n",
    "        top: 0;\n",
    "        background: #f2f2f2;\n",
    "        z-index: 2;\n",
    "      }\n",
    "      table.pivot th::after {\n",
    "        content: \"\";\n",
    "        float: right;\n",
    "        opacity: 0.4;\n",
    "      }\n",
    "      table.pivot th.sorted-asc::after {\n",
    "        content: \" ‚ñ≤\";\n",
    "      }\n",
    "      table.pivot th.sorted-desc::after {\n",
    "        content: \" ‚ñº\";\n",
    "      }\n",
    "      /* Row coloring by status */\n",
    "      table.pivot tr[data-status=\"dead\"] {\n",
    "         background-color: #fdecea;  /* light red */\n",
    "      }\n",
    "      table.pivot tr[data-status=\"dead\"] td:nth-child(2) i {\n",
    "          color: #1565c0;\n",
    "        }\n",
    "\n",
    "      table.pivot tr[data-status=\"error\"] {\n",
    "          background-color: #fff4e5;  /* light orange */\n",
    "      }\n",
    "\n",
    "      table.pivot td a {\n",
    "        color: #0645ad;\n",
    "        text-decoration: none;\n",
    "      }\n",
    "      table.pivot td a:hover {\n",
    "        text-decoration: underline;\n",
    "      }\n",
    "      .meta {\n",
    "        background: #f8f8f8;\n",
    "        border: 1px solid #ccc;\n",
    "        padding: 12px;\n",
    "        margin-bottom: 20px;\n",
    "        font-size: 13px;\n",
    "      }\n",
    "      .meta h2 {\n",
    "        margin-top: 0;\n",
    "      }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "\n",
    "    # --- JavaScript (sortering) ---\n",
    "    js = \"\"\"\n",
    "    <script>\n",
    "    document.addEventListener('DOMContentLoaded', () => {\n",
    "        // Propagate status from first cell to row\n",
    "        document.querySelectorAll(\"table.pivot tbody tr\").forEach(row => {\n",
    "            const statusCell = row.querySelector(\".status-icon\");\n",
    "            if (statusCell) {\n",
    "                row.dataset.status = statusCell.dataset.status;\n",
    "            }\n",
    "        });\n",
    "        let showOnlyBroken = false;\n",
    "\n",
    "        document.querySelectorAll(\".status-icon\").forEach(icon => {\n",
    "            icon.addEventListener(\"click\", event => {\n",
    "                event.stopPropagation(); // prevent column sort\n",
    "                showOnlyBroken = !showOnlyBroken;\n",
    "        \n",
    "                document.querySelectorAll(\"table.pivot tbody tr\").forEach(row => {\n",
    "                    if (showOnlyBroken) {\n",
    "                        row.style.display =\n",
    "                            row.dataset.status === \"dead\" ? \"\" : \"none\";\n",
    "                    } else {\n",
    "                        row.style.display = \"\";\n",
    "                    }\n",
    "                });\n",
    "            });\n",
    "        });\n",
    "\n",
    "        document.querySelectorAll(\"table.pivot th\").forEach((header, colIndex) => {\n",
    "            header.addEventListener(\"click\", () => {\n",
    "                const table = header.closest(\"table\");\n",
    "                const tbody = table.querySelector(\"tbody\");\n",
    "                const rows = Array.from(tbody.querySelectorAll(\"tr\"));\n",
    "                const asc = !header.classList.contains(\"sorted-asc\");\n",
    "\n",
    "                rows.sort((a, b) => {\n",
    "                    const A = a.children[colIndex].innerText.trim();\n",
    "                    const B = b.children[colIndex].innerText.trim();\n",
    "                    const numA = parseFloat(A.replace(\",\", \".\"));\n",
    "                    const numB = parseFloat(B.replace(\",\", \".\"));\n",
    "                    if (!isNaN(numA) && !isNaN(numB)) {\n",
    "                        return asc ? numA - numB : numB - numA;\n",
    "                    }\n",
    "                    return asc ? A.localeCompare(B) : B.localeCompare(A);\n",
    "                });\n",
    "\n",
    "                table.querySelectorAll(\"th\").forEach(th =>\n",
    "                    th.classList.remove(\"sorted-asc\", \"sorted-desc\")\n",
    "                );\n",
    "                header.classList.add(asc ? \"sorted-asc\" : \"sorted-desc\");\n",
    "                rows.forEach(row => tbody.appendChild(row));\n",
    "            });\n",
    "        });\n",
    "    });\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    status_counts = df[\"status\"].value_counts()\n",
    "    \n",
    "    num_ok = status_counts.get(\"ok\", 0)\n",
    "    num_dead = status_counts.get(\"dead\", 0)\n",
    "    num_error = status_counts.get(\"error\", 0)\n",
    "    num_total = len(df)\n",
    "\n",
    "    # --- Metadata ---\n",
    "    meta_html = f\"\"\"\n",
    "    <div class=\"meta\">\n",
    "      <h2>Summary</h2>\n",
    "    \n",
    "      <p><strong>Rerun:</strong> {rerun_ts}</p>\n",
    "      <p><strong>Script:</strong>\n",
    "         <a href=\"{SCRIPT_URL}\" target=\"_blank\">{SCRIPT_NAME}</a>\n",
    "      </p>\n",
    "    \n",
    "      <p>\n",
    "        <strong>Links checked:</strong> {num_total}<br>\n",
    "        <strong style=\"color:#2e7d32;\">OK:</strong> {num_ok} ({pct_ok}%)<br>\n",
    "        <strong style=\"color:#c62828;\">Broken:</strong> {num_dead} ({pct_dead}%)<br>\n",
    "        &nbsp;&nbsp;‚Ü≥ Archived: {num_dead_archived}<br>\n",
    "        &nbsp;&nbsp;‚Ü≥ Lost: {num_dead_lost}<br>\n",
    "        <strong style=\"color:#ef6c00;\">Errors:</strong> {num_error} ({pct_error}%)\n",
    "      </p>\n",
    "      <p><strong>Issue:</strong>\n",
    "         <a href=\"{issue_url}\" target=\"_blank\">{issue_url.split(\"/\")[-1]}</a>\n",
    "      </p>\n",
    "    \n",
    "      <p><strong>Datak√§llor:</strong><br>\n",
    "         Wikidata<br>\n",
    "         MediaWiki API ‚Äì exturlusage\n",
    "      </p>\n",
    "    \n",
    "      <h2>Domains with broken links</h2>\n",
    "      <p>Top domains ranked by broken-link impact.</p>\n",
    "      {domain_table_html}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # --- Slutlig HTML ---\n",
    "    html = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "      <meta charset=\"utf-8\">\n",
    "      <title>esv.se links in Wikipedia</title>\n",
    "      <link rel=\"stylesheet\"\n",
    "            href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css\">\n",
    "      {css}\n",
    "    </head>\n",
    "    <body>\n",
    "      <h1>Wikipedia ‚Üí ESV v1</h1>\n",
    "      {meta_html}\n",
    "      <p>Sorterbar tabell. Klicka p√• kolumnrubriker f√∂r sortering.</p>\n",
    "      {html_table}\n",
    "      {js}\n",
    "      <h2>Broken-link summary by Wikipedia language</h2>\n",
    "     <p>\n",
    "       Languages ranked by broken-link impact (broken + error links).\n",
    "     </p>\n",
    "    {lang_table_html}\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    out_path.write_text(html, encoding=\"utf-8\")\n",
    "    print(f\"‚úÖ HTML skapad: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371c9d2-6e5a-444b-8f91-6a599b2a1adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_sortable_html_df_regeringen(df_esv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761dcf7-c74a-42e9-91e1-99e44e932b73",
   "metadata": {},
   "outputs": [],
   "source": [
    " # End timer and calculate duration\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time# Bygg audit-lager f√∂r den h√§r etappen\n",
    "\n",
    "# Print current date and total time\n",
    "print(\"Date:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "minutes, seconds = divmod(elapsed_time, 60)\n",
    "print(\"Total time elapsed: {:02.0f} minutes {:05.2f} seconds\".format(minutes, seconds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b185e4-9345-492c-a4cc-d16059de7daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
